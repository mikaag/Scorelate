{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as sk_metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import tempfile\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import metrics\n",
    "import pymssql\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import plot_importance\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "# modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# for modeling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "random_state = 2023\n",
    "\n",
    "# Preset matplotlib figure sizes.\n",
    "matplotlib.rcParams['figure.figsize'] = [9, 6]\n",
    "\n",
    "print(tf.__version__)\n",
    "# To make the results reproducible, set the random seed value.\n",
    "tf.random.set_seed(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def get_column_index(cursor, column_name):\n",
    "    for index, col in enumerate(cursor.description):\n",
    "        if col[0] == column_name:\n",
    "            return index\n",
    "additional_data_headers = [\"RentMortgagePayment\" ,\"TotalIncome\" ,\"RentMortgage\" ,\"CarPayment\" ,\"Expenses\" ,\"AvailableIncome\" ,\"Miles\"]\n",
    "additional_data_sql = \"VIN,\"\n",
    "for i, header in enumerate(additional_data_headers):\n",
    "    additional_data_sql += header\n",
    "    if i!=len(additional_data_headers)-1:\n",
    "        additional_data_sql+=','"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26508it [00:34, 779.36it/s] \n",
      "/var/folders/kh/np0tdw052gg77h97rt6rm3l80000gn/T/ipykernel_71904/1059541156.py:81: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df.fillna(df.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "conn = pymssql.connect(server='localhost', user='sa', password='Passw0rd!', database='Loans_2023_01_27')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "headers = []\n",
    "rows = []\n",
    "\n",
    "# Underwriting Data\n",
    "cursor.execute(\"SELECT * FROM dbo.UnderwritingData\")\n",
    "\n",
    "for entity in cursor.description:\n",
    "    headers.append(entity[0])\n",
    "\n",
    "vin_index = get_column_index(cursor, \"VIN\")\n",
    "\n",
    "res = cursor.fetchone()\n",
    "while res:\n",
    "    row = [element for element in res]\n",
    "    if row[vin_index] is not None:\n",
    "        rows.append(row)\n",
    "    res = cursor.fetchone()\n",
    "\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "ids = [i for i in range(0, len(df))]\n",
    "default_status = [\"NA\" for _ in range(len(df))]\n",
    "default_delq = [\"NA\" for i in range(len(df))]\n",
    "default_apr = [\"NA\" for _ in range(len(df))]\n",
    "df[\"ID\"] = ids\n",
    "df[\"APR\"] = default_apr\n",
    "df[\"Status\"] = default_status\n",
    "df[\"Delq\"] = default_delq\n",
    "df = df[df['OpeningBalance']!=0]\n",
    "\n",
    "\n",
    "#Raw algorithm data\n",
    "headers = []\n",
    "rawAlgRows =[]\n",
    "cursor.execute(\"Select * FROM dbo.RawAlgorithmData\")\n",
    "\n",
    "for entity in cursor.description:\n",
    "    headers.append(entity[0])\n",
    "\n",
    "vin_index = get_column_index(cursor, \"Vin6\")\n",
    "\n",
    "res = cursor.fetchone()\n",
    "while res:\n",
    "    row = [element for element in res]\n",
    "    if row[vin_index] is not None:\n",
    "        rawAlgRows.append(row)\n",
    "    res = cursor.fetchone()\n",
    "\n",
    "rawAlgDf = pd.DataFrame(rawAlgRows, columns=headers)\n",
    "#prune extra space from end of vins\n",
    "rawAlgDf['Vin6'] = rawAlgDf['Vin6'].apply(lambda x: x.strip())\n",
    "df['VIN'] = df['VIN'].apply(lambda x: x.strip())\n",
    "\n",
    "\n",
    "#matching by credit score\n",
    "for idx, row in tqdm(rawAlgDf.iterrows()):\n",
    "    vin = row[\"Vin6\"]\n",
    "    vinsFromUnder = df[df[\"VIN\"]==vin]\n",
    "\n",
    "\n",
    "    for index, match in vinsFromUnder.iterrows():\n",
    "        matchID = match[\"ID\"]\n",
    "        underwritingCreditScore = (int)(match[\"CreaditScore\"])\n",
    "        rawCreditScore = (int)(row[\"Score\"])\n",
    "\n",
    "        #we don't want to match if the scores are zero, since that means they are missing\n",
    "        if rawCreditScore==0:\n",
    "            continue\n",
    "\n",
    "        if underwritingCreditScore==rawCreditScore:\n",
    "            df.loc[df[\"ID\"]==matchID,\"Status\"]=row[\"ProcStatsCd\"]\n",
    "            df.loc[df[\"ID\"]==matchID,\"Delq\"]=row[\"Delq\"]\n",
    "            df.loc[df[\"ID\"]==matchID, \"APR\"] = int(row[\"Apr\"] * 100) if row[\"Apr\"] is not None else None #convert apr to an int\n",
    "\n",
    "df = df[(df['Status']=='CO') | (df['Status']=='CL')]\n",
    "df['Status'].replace(to_replace=['CO', 'CL'], value=[0,1], inplace=True)\n",
    "df['HomeOwner'].replace(to_replace=['N', 'Y'], value=[0,1], inplace=True)\n",
    "df['DelqPct'] = df.apply(lambda row : (100*row['Delq'])/row['OpeningBalance'],axis=1)\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "#TODO maybe put back: CreaditScore, CurrentPaymentsMade, DelqPct\n",
    "df = df[[\"OpeningBalance\",\"Salary\",\"Term\",\"VehicleYear\",\"LTV\",\"DTI\",\"TradelinesTotal\",\"TradelinesBalance\",\"Reposessions\",\"Bankrupcies\",\"Chageoff\",\"Mortgage\",\"NinetyDaysDelinquent\",\"InquiresTotal\",\"OpenTotal\",\"ClosedTotalTermsNotPaid\",\"LatePaymentHistory001230\",\"LatePaymentHistory001260\",\"LatePaymentHistory001290Plus\",\"PaidAccounts\",\"InquiriesLast6Months\",\"OpenTotalInBadStatus\",\"RentMortgage\",\"CashDown\",\"HomeOwner\", \"APR\", \"CreaditScore\", \"DelqPct\", \"Status\"]]\n",
    "\n",
    "#outlier handling\n",
    "for col in df.columns:\n",
    "    if(col in [\"Status\", \"DelqPct\", \"CreaditScore\", \"HomeOwner\", \"Reposessions\", \"Chageoff\", \"APR\"]):\n",
    "        continue\n",
    "    percentiles = df[col].quantile([0.00, 0.999]).values\n",
    "    df.loc[df[col]<=percentiles[0], col] = percentiles[0]\n",
    "    df.loc[df[col]>=percentiles[1], col] = percentiles[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NinetyDaysDelinquent', 'OpenTotalInBadStatus', 'Salary', 'CreaditScore', 'CashDown', 'Term', 'APR', 'OpeningBalance']\n",
      "(6721, 8)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "corrs = dict()\n",
    "\n",
    "for col in df.columns:\n",
    "    if col == \"DelqPct\" or col==\"Status\":\n",
    "        continue\n",
    "    corr, _ = pearsonr(df[col], df[\"DelqPct\"])\n",
    "    corrs[col] = abs(corr)\n",
    "\n",
    "corrs = {k: v for k, v in sorted(corrs.items(), key=lambda item: item[1])}\n",
    "\n",
    "goodCols = []\n",
    "\n",
    "for col, score in corrs.items():\n",
    "    if score>=0.1:\n",
    "        goodCols.append(col)\n",
    "\n",
    "print(goodCols)\n",
    "goodCols.append(\"Status\")\n",
    "\n",
    "dfCorr = df[goodCols]\n",
    "# print(dfCorr)\n",
    "\n",
    "X=np.array(dfCorr.iloc[:,:-1])\n",
    "Y = dfCorr.iloc[:,-1:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dfCorr.iloc[:,:-1], dfCorr.iloc[:,-1:], test_size=0.2, random_state=42)\n",
    "print(X_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 16)                144       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 15:35:35.664756: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673/673 [==============================] - ETA: 0s - loss: 15.9118 - accuracy: 0.5341"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 15:35:42.357882: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673/673 [==============================] - 8s 11ms/step - loss: 15.9118 - accuracy: 0.5341 - val_loss: 4.5705 - val_accuracy: 0.6306\n",
      "Epoch 2/80\n",
      "673/673 [==============================] - 7s 10ms/step - loss: 9.0070 - accuracy: 0.5269 - val_loss: 8.1163 - val_accuracy: 0.4557\n",
      "Epoch 3/80\n",
      "673/673 [==============================] - 7s 10ms/step - loss: 6.0096 - accuracy: 0.5276 - val_loss: 2.3333 - val_accuracy: 0.6151\n",
      "Epoch 4/80\n",
      "673/673 [==============================] - 7s 10ms/step - loss: 7.3351 - accuracy: 0.5248 - val_loss: 5.2147 - val_accuracy: 0.5158\n",
      "Epoch 5/80\n",
      "673/673 [==============================] - 5s 8ms/step - loss: 6.0681 - accuracy: 0.5269 - val_loss: 12.9662 - val_accuracy: 0.4598\n",
      "Epoch 6/80\n",
      "673/673 [==============================] - 5s 7ms/step - loss: 6.0743 - accuracy: 0.5282 - val_loss: 13.1593 - val_accuracy: 0.5407\n",
      "Epoch 7/80\n",
      "673/673 [==============================] - 5s 7ms/step - loss: 9.6086 - accuracy: 0.5225 - val_loss: 4.4268 - val_accuracy: 0.5199\n",
      "Epoch 8/80\n",
      "673/673 [==============================] - 5s 7ms/step - loss: 7.2551 - accuracy: 0.5276 - val_loss: 11.8264 - val_accuracy: 0.4616\n",
      "Epoch 9/80\n",
      "673/673 [==============================] - 5s 7ms/step - loss: 6.3690 - accuracy: 0.5286 - val_loss: 4.1801 - val_accuracy: 0.4688\n",
      "Epoch 10/80\n",
      "673/673 [==============================] - 5s 7ms/step - loss: 5.9581 - accuracy: 0.5222 - val_loss: 25.2960 - val_accuracy: 0.4598\n",
      "Epoch 11/80\n",
      "673/673 [==============================] - 5s 7ms/step - loss: 6.2783 - accuracy: 0.5166 - val_loss: 26.7680 - val_accuracy: 0.5419\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build a model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(X.shape[1],), activation='relu')) # Add an input shape! (features,)\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# early stopping callback\n",
    "# This callback will stop the training when there is no improvement in\n",
    "# the validation loss for 10 consecutive epochs.\n",
    "es = EarlyStopping(monitor='val_accuracy',\n",
    "                                   mode='max', # don't minimize the accuracy!\n",
    "                                   patience=10,\n",
    "                                   restore_best_weights=True)\n",
    "\n",
    "# now we just update our model fit call\n",
    "history = model.fit(X,\n",
    "                    Y,\n",
    "                    callbacks=[es],\n",
    "                    epochs=80, # you can set this to a big number!\n",
    "                    batch_size=10,\n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}