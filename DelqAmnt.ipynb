{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as sk_metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import tempfile\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import metrics\n",
    "import pymssql\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import plot_importance\n",
    "import yaml\n",
    "\n",
    "\n",
    "# Preset matplotlib figure size\n",
    "# s.\n",
    "matplotlib.rcParams['figure.figsize'] = [9, 6]\n",
    "\n",
    "print(tf.__version__)\n",
    "# To make the results reproducible, set the random seed value.\n",
    "tf.random.set_seed(22)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'server': {'server': 'localhost', 'user': 'sa', 'pwd': 'Passw0rd!', 'database': 'Loans_2023_01_27'}, 'predict': {'Percent': True, 'Num': 'Delq', 'Denom': 'OpeningBalance'}, 'Keys': {'Key1': 'VIN', 'Key2': 'Vin6'}, 'Databases': {'db1': 'dbo.UnderwritingData', 'db2': 'dbo.RawAlgorithmData'}, 'include': ['OpeningBalance', 'Salary', 'Term', 'VehicleYear', 'LTV', 'DTI', 'TradelinesTotal', 'TradelinesBalance', 'Reposessions', 'Bankrupcies', 'Chageoff', 'Mortgage', 'NinetyDaysDelinquent', 'InquiresTotal', 'OpenTotal', 'ClosedTotalTermsNotPaid', 'LatePaymentHistory001230', 'LatePaymentHistory001260', 'LatePaymentHistory001290Plus', 'PaidAccounts', 'InquiriesLast6Months', 'OpenTotalInBadStatus', 'RentMortgage', 'CashDown', 'HomeOwner', 'APR', 'Status'], 'outliers': ['Status', 'DelqPct', 'CreaditScore', 'HomeOwner', 'Reposessions', 'Chageoff', 'APR']}\n"
     ]
    }
   ],
   "source": [
    "with open(\"config.yaml\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "server_info = config[\"server\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DatabaseLoader:\n",
    "    def __init__(self, _server_info):\n",
    "        _conn = pymssql.connect(server=server_info['name'], user=server_info['user'], password=server_info['password'], database=server_info['Loans_2023_01_27'])\n",
    "\n",
    "        self._cursor = conn.cursor()\n",
    "\n",
    "    def get_column_index(self, _column_name):\n",
    "        for index, col in enumerate(cursor.description):\n",
    "            if col[0] == _column_name:\n",
    "                return index\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conn = pymssql.connect(server=server_info['name'], user=server_info['user'], password=server_info['password'], database=server_info['Loans_2023_01_27'])\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def get_column_index(cursor, column_name):\n",
    "    for index, col in enumerate(cursor.description):\n",
    "        if col[0] == column_name:\n",
    "            return index\n",
    "\n",
    "additional_data_headers = [\"RentMortgagePayment\" ,\"TotalIncome\" ,\"RentMortgage\" ,\"CarPayment\" ,\"Expenses\" ,\"AvailableIncome\" ,\"Miles\"]\n",
    "additional_data_sql = \"VIN,\"\n",
    "for i, header in enumerate(additional_data_headers):\n",
    "    additional_data_sql += header\n",
    "    if i!=len(additional_data_headers)-1:\n",
    "        additional_data_sql+=','\n",
    "\n",
    "headers = []\n",
    "rows = []\n",
    "\n",
    "# Underwriting Data\n",
    "cursor.execute(\"SELECT * FROM dbo.UnderwritingData\")\n",
    "\n",
    "for entity in cursor.description:\n",
    "    headers.append(entity[0])\n",
    "\n",
    "vin_index = get_column_index(cursor, \"VIN\")\n",
    "\n",
    "res = cursor.fetchone()\n",
    "while res:\n",
    "    row = [element for element in res]\n",
    "    if row[vin_index] is not None:\n",
    "        row[vin_index] = row[vin_index]\n",
    "        rows.append(row)\n",
    "    res = cursor.fetchone()\n",
    "\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "\n",
    "#Additional Data\n",
    "cursor.execute(\"Select {vCols} FROM dbo.VerificationsDec\".format(vCols = additional_data_sql))\n",
    "\n",
    "addl_data_rows = []\n",
    "res = cursor.fetchone()\n",
    "\n",
    "while res:\n",
    "    row = [element for element in res]\n",
    "    row[0] = row[0].strip()\n",
    "    addl_data_rows.append(row)\n",
    "    res = cursor.fetchone()\n",
    "\n",
    "print(\"Assigning Additional Entities\")\n",
    "for data in tqdm(addl_data_rows):\n",
    "    df.loc[df['VIN']==data[0].strip(), additional_data_headers] = data[1:]\n",
    "\n",
    "#Results from RawAlgorithmData\n",
    "cursor.execute(\"SELECT Vin6,ProcStatsCd,Delq FROM dbo.RawAlgorithmData\")\n",
    "res = cursor.fetchone()\n",
    "loan_results = dict()\n",
    "delq_results = dict()\n",
    "while res:\n",
    "    vin6 = res[0].strip()\n",
    "    if len(vin6)==17:\n",
    "        # print(\"adding\")\n",
    "        loan_results[vin6] = res[1].strip()\n",
    "        delq_results[vin6] = res[2]\n",
    "    res = cursor.fetchone()\n",
    "\n",
    "default_result = [\"NA\" for i in range(len(df))]\n",
    "default_delq = [\"NA\" for i in range(len(df))]\n",
    "df['Result'] = default_result\n",
    "df['Delq'] = default_delq\n",
    "\n",
    "df = df[df['OpeningBalance']!=0]\n",
    "\n",
    "print(\"Assigning Results\")\n",
    "for vin6, res in tqdm(loan_results.items()):\n",
    "    # print(vin6)\n",
    "    df.loc[df['VIN'] == vin6, ['Result', 'Delq']] = [res, delq_results[vin6]]\n",
    "    # print(df.loc[df['VIN'] == vin6])\n",
    "\n",
    "df = df[[\"RentMortgagePayment\" ,\"TotalIncome\" ,\"CarPayment\" ,\"Expenses\" ,\"AvailableIncome\" ,\"Miles\", \"OpeningBalance\",\"Salary\",\"Term\",\"VehicleYear\",\"CreaditScore\",\"LTV\",\"DTI\",\"TradelinesTotal\",\"TradelinesBalance\",\"Reposessions\",\"Bankrupcies\",\"Chageoff\",\"Mortgage\",\"NinetyDaysDelinquent\",\"InquiresTotal\",\"OpenTotal\",\"ClosedTotalTermsNotPaid\",\"LatePaymentHistory001230\",\"LatePaymentHistory001260\",\"LatePaymentHistory001290Plus\",\"PaidAccounts\",\"InquiriesLast6Months\",\"OpenTotalInBadStatus\",\"CurrentPaymentsMade\",\"RentMortgage\",\"CashDown\",\"HomeOwner\", \"Delq\", \"Result\"]]\n",
    "\n",
    "print(df)\n",
    "dfCLOnly = df.copy(deep=True)\n",
    "dfCLOnly = dfCLOnly[(dfCLOnly['Result']=='CL')]\n",
    "dfCLOnly['Result'].replace(to_replace=['CO', 'CL'], value=[0,1], inplace=True)\n",
    "dfCLOnly['HomeOwner'].replace(to_replace=['N', 'Y'], value=[0,1], inplace=True)\n",
    "dfCLOnly['DelqPct'] = dfCLOnly.apply(lambda row : (100*row['Delq'])/row['OpeningBalance'],axis=1)\n",
    "dfCLOnly.fillna(dfCLOnly.mean(), inplace=True)\n",
    "\n",
    "\n",
    "df = df[(df['Result']=='CO') | (df['Result']=='CL')]\n",
    "df['Result'].replace(to_replace=['CO', 'CL'], value=[0,1], inplace=True)\n",
    "df['HomeOwner'].replace(to_replace=['N', 'Y'], value=[0,1], inplace=True)\n",
    "df['DelqPct'] = df.apply(lambda row : (100*row['Delq'])/row['OpeningBalance'],axis=1)\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "df = df[[\"RentMortgagePayment\" ,\"TotalIncome\" ,\"CarPayment\" ,\"Expenses\" ,\"AvailableIncome\" ,\"Miles\", \"OpeningBalance\",\"Salary\",\"Term\",\"VehicleYear\",\"CreaditScore\",\"LTV\",\"DTI\",\"TradelinesTotal\",\"TradelinesBalance\",\"Reposessions\",\"Bankrupcies\",\"Chageoff\",\"Mortgage\",\"NinetyDaysDelinquent\",\"InquiresTotal\",\"OpenTotal\",\"ClosedTotalTermsNotPaid\",\"LatePaymentHistory001230\",\"LatePaymentHistory001260\",\"LatePaymentHistory001290Plus\",\"PaidAccounts\",\"InquiriesLast6Months\",\"OpenTotalInBadStatus\",\"CurrentPaymentsMade\",\"RentMortgage\",\"CashDown\",\"HomeOwner\", \"DelqPct\"]]\n",
    "\n",
    "dfCLOnly = dfCLOnly[[\"RentMortgagePayment\" ,\"TotalIncome\" ,\"CarPayment\" ,\"Expenses\" ,\"AvailableIncome\" ,\"Miles\", \"OpeningBalance\",\"Salary\",\"Term\",\"VehicleYear\",\"CreaditScore\",\"LTV\",\"DTI\",\"TradelinesTotal\",\"TradelinesBalance\",\"Reposessions\",\"Bankrupcies\",\"Chageoff\",\"Mortgage\",\"NinetyDaysDelinquent\",\"InquiresTotal\",\"OpenTotal\",\"ClosedTotalTermsNotPaid\",\"LatePaymentHistory001230\",\"LatePaymentHistory001260\",\"LatePaymentHistory001290Plus\",\"PaidAccounts\",\"InquiriesLast6Months\",\"OpenTotalInBadStatus\",\"CurrentPaymentsMade\",\"RentMortgage\",\"CashDown\",\"HomeOwner\", \"DelqPct\"]]\n",
    "print(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_outliers(df,columns,n_std):\n",
    "    for col in columns:\n",
    "        print('Working on column: {}'.format(col))\n",
    "\n",
    "        mean = df[col].mean()\n",
    "        sd = df[col].std()\n",
    "\n",
    "        df = df[(df[col] <= mean+(n_std*sd))]\n",
    "\n",
    "    return df\n",
    "\n",
    "df2 = remove_outliers(df, df.columns, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # fig, axes = plt.subplots(ncols=3)\n",
    "# # for i, yvar in enumerate(df.columns):\n",
    "# #     axes[i].scatter(df['Result'],df[yvar])\n",
    "#\n",
    "# df3 =  remove_outliers(df2, df2.columns, 3)\n",
    "#\n",
    "# pp = sns.pairplot(data=df2,\n",
    "#                   y_vars=[\"DelqPct\"],\n",
    "#                   x_vars=df.columns)\n",
    "#\n",
    "# pp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df2.iloc[:,:-1], df2.iloc[:,-1:], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "resdict= dict()\n",
    "rdict = dict()\n",
    "\n",
    "num_features = [i for i in range(1, len(df.columns)-2)]\n",
    "\n",
    "# for nf in tqdm(num_features):\n",
    "#     linReg = LinearRegression()\n",
    "#     rfe = RFE(estimator = linReg, n_features_to_select = nf)\n",
    "#     rfe.fit(x_train, y_train.values.ravel())\n",
    "#\n",
    "#\n",
    "#     train_pred = rfe.predict(x_train)\n",
    "#     test_pred = rfe.predict(x_test)\n",
    "#\n",
    "#     resdict[nf] = np.sqrt(metrics.mean_squared_error(y_test, test_pred))\n",
    "#     rdict[nf] = metrics.r2_score(y_test, test_pred)\n",
    "\n",
    "print(resdict)\n",
    "print(rdict)\n",
    "\n",
    "linReg = LinearRegression()\n",
    "rfe = RFE(estimator = linReg, n_features_to_select = 59)\n",
    "rfe.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "\n",
    "train_pred = rfe.predict(x_train)\n",
    "test_pred = rfe.predict(x_test)\n",
    "\n",
    "print(\"LinearRegression\")\n",
    "print(\"R^2 : \", metrics.r2_score(y_test, test_pred))\n",
    "print(\"MAE :\", metrics.mean_absolute_error(y_test,test_pred))\n",
    "print(\"RMSE: \",np.sqrt(metrics.mean_squared_error(y_test, test_pred)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(y_train)\n",
    "\n",
    "# x_train = sm.add_constant(x_train)\n",
    "for p1 in df.columns:\n",
    "    for p2 in df.columns:\n",
    "        if p1==p2:\n",
    "            continue\n",
    "        model = smf.ols(formula='DelqPct ~ ' + p1 + '*'+p2, data =df).fit()\n",
    "        params = model.params\n",
    "        print(p1 + \" and \"+p2)\n",
    "        print(\"Coefficients: \")\n",
    "        print(params)\n",
    "        print()\n",
    "        print(\"P Values: \")\n",
    "        print(model.pvalues)\n",
    "        print()\n",
    "        print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# x_test = sm.add_constant(x_test)\n",
    "#\n",
    "# print(est.predict(x_train[:5]))\n",
    "# print(y_train[:5])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TensorFlow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_outliers(df,columns,n_std):\n",
    "    for col in columns:\n",
    "        print('Working on column: {}'.format(col))\n",
    "\n",
    "        mean = df[col].mean()\n",
    "        sd = df[col].std()\n",
    "\n",
    "        df = df[(df[col] <= mean+(n_std*sd))]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = remove_outliers(df, df.columns, 3)\n",
    "\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    df.iloc[:,:-1], df.iloc[:,-1:], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(train_features))\n",
    "print(normalizer.mean.numpy())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dnn_model = build_and_compile_model(normalizer)\n",
    "dnn_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "history = dnn_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.ylim([0, 10])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [DelqPct]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "plot_loss(history)\n",
    "\n",
    "#Overfitting is when the model fits the training data too closely, and the loss keeps decreasing while the val_loss is stale, or increases.\n",
    "#which looks to be exactly what is happening here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_results = dict()\n",
    "test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)\n",
    "pd.DataFrame(test_results, index=['Mean absolute error [DelqPCT]']).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_predictions = dnn_model.predict(test_features).flatten()\n",
    "\n",
    "print(test_predictions[:5])\n",
    "print(test_labels[:5])\n",
    "\n",
    "error = test_predictions.reshape(test_predictions.shape[0],1) - test_labels\n",
    "plt.hist(error, bins=25)\n",
    "plt.xlabel('Prediction Error [DelqPct]')\n",
    "_ = plt.ylabel('Count')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### XGBoost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgdata = df.copy(deep=True)\n",
    "for x in tqdm(range(1)):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(xgdata.iloc[:,:-1], xgdata.iloc[:,-1:], test_size=0.2)\n",
    "\n",
    "    train = xgb.DMatrix(x_train, label=y_train)\n",
    "    test = xgb.DMatrix(x_test, label=y_test)\n",
    "\n",
    "    param = {\n",
    "        'eta': 0.01,\n",
    "        'objective': 'reg:squarederror',\n",
    "    }\n",
    "    epochs = 500\n",
    "\n",
    "    model = xgb.train(param, train, epochs)\n",
    "\n",
    "    predictions = model.predict(test)\n",
    "\n",
    "    y = []\n",
    "\n",
    "    for z in predictions:\n",
    "        y.append(np.argmax(z))\n",
    "\n",
    "    acc = round(metrics.mean_squared_error(y_test, y, squared=False), 3)\n",
    "    model.save_model('Models/Delq/XGBoost_{}%_Scorelate.json'.format(acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgb_ml = xgb.Booster()\n",
    "\n",
    "xgb_ml.load_model('Models/Delq/XGBoost_6.966%_Scorelate.json')\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1:], test_size=0.2)\n",
    "print(xgb_ml.predict(xgb.DMatrix(x_test[:5])))\n",
    "print(y_test[:5])\n",
    "\n",
    "# plot feature importance\n",
    "plot_importance(xgb_ml)\n",
    "plt.show()\n",
    "\n",
    "res = xgb_ml.predict(xgb.DMatrix(x_test))\n",
    "preds = []\n",
    "actual = []\n",
    "for pred in res:\n",
    "    if(pred<0.1):\n",
    "        preds.append(\"Paid\")\n",
    "    else:\n",
    "        preds.append(\"CO\")\n",
    "\n",
    "for result in y_test[\"DelqPct\"]:\n",
    "    if result == 0.0:\n",
    "        actual.append(\"Paid\")\n",
    "    else:\n",
    "        actual.append(\"CO\")\n",
    "\n",
    "paidandpredpaid = 0\n",
    "paidandpredco = 0\n",
    "coandpredpaid = 0\n",
    "coandpredco = 0\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    if preds[i]==\"Paid\" and actual[i]==\"Paid\":\n",
    "        paidandpredpaid+=1\n",
    "    elif preds[i]==\"CO\" and actual[i]==\"Paid\":\n",
    "        paidandpredco+=1\n",
    "    elif preds[i]==\"Paid\" and actual[i]==\"CO\":\n",
    "        coandpredpaid+=1\n",
    "    elif preds[i]==\"CO\" and actual[i]==\"CO\":\n",
    "        coandpredco+=1\n",
    "\n",
    "print(\"Paid and Pred Paid: \", paidandpredpaid)\n",
    "print(\"Paid and Pred CO: \", paidandpredco)\n",
    "print(\"CO and Pred Paid: \", coandpredpaid)\n",
    "print(\"CO and Pred CO: \", coandpredco)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}