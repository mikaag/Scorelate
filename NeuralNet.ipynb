{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as sk_metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import tempfile\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import metrics\n",
    "import pymssql\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import plot_importance\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "\n",
    "random_state = 2023\n",
    "\n",
    "# Preset matplotlib figure sizes.\n",
    "matplotlib.rcParams['figure.figsize'] = [9, 6]\n",
    "\n",
    "print(tf.__version__)\n",
    "# To make the results reproducible, set the random seed value.\n",
    "tf.random.set_seed(22)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def get_column_index(cursor, column_name):\n",
    "    for index, col in enumerate(cursor.description):\n",
    "        if col[0] == column_name:\n",
    "            return index\n",
    "additional_data_headers = [\"RentMortgagePayment\" ,\"TotalIncome\" ,\"RentMortgage\" ,\"CarPayment\" ,\"Expenses\" ,\"AvailableIncome\" ,\"Miles\"]\n",
    "additional_data_sql = \"VIN,\"\n",
    "for i, header in enumerate(additional_data_headers):\n",
    "    additional_data_sql += header\n",
    "    if i!=len(additional_data_headers)-1:\n",
    "        additional_data_sql+=','"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26508it [00:30, 859.65it/s] \n",
      "/var/folders/kh/np0tdw052gg77h97rt6rm3l80000gn/T/ipykernel_70814/4149204941.py:81: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df.fillna(df.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "conn = pymssql.connect(server='localhost', user='sa', password='Passw0rd!', database='Loans_2023_01_27')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "headers = []\n",
    "rows = []\n",
    "\n",
    "# Underwriting Data\n",
    "cursor.execute(\"SELECT * FROM dbo.UnderwritingData\")\n",
    "\n",
    "for entity in cursor.description:\n",
    "    headers.append(entity[0])\n",
    "\n",
    "vin_index = get_column_index(cursor, \"VIN\")\n",
    "\n",
    "res = cursor.fetchone()\n",
    "while res:\n",
    "    row = [element for element in res]\n",
    "    if row[vin_index] is not None:\n",
    "        rows.append(row)\n",
    "    res = cursor.fetchone()\n",
    "\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "ids = [i for i in range(0, len(df))]\n",
    "default_status = [\"NA\" for _ in range(len(df))]\n",
    "default_delq = [\"NA\" for i in range(len(df))]\n",
    "default_apr = [\"NA\" for _ in range(len(df))]\n",
    "df[\"ID\"] = ids\n",
    "df[\"APR\"] = default_apr\n",
    "df[\"Status\"] = default_status\n",
    "df[\"Delq\"] = default_delq\n",
    "df = df[df['OpeningBalance']!=0]\n",
    "\n",
    "\n",
    "#Raw algorithm data\n",
    "headers = []\n",
    "rawAlgRows =[]\n",
    "cursor.execute(\"Select * FROM dbo.RawAlgorithmData\")\n",
    "\n",
    "for entity in cursor.description:\n",
    "    headers.append(entity[0])\n",
    "\n",
    "vin_index = get_column_index(cursor, \"Vin6\")\n",
    "\n",
    "res = cursor.fetchone()\n",
    "while res:\n",
    "    row = [element for element in res]\n",
    "    if row[vin_index] is not None:\n",
    "        rawAlgRows.append(row)\n",
    "    res = cursor.fetchone()\n",
    "\n",
    "rawAlgDf = pd.DataFrame(rawAlgRows, columns=headers)\n",
    "#prune extra space from end of vins\n",
    "rawAlgDf['Vin6'] = rawAlgDf['Vin6'].apply(lambda x: x.strip())\n",
    "df['VIN'] = df['VIN'].apply(lambda x: x.strip())\n",
    "\n",
    "\n",
    "#matching by credit score\n",
    "for idx, row in tqdm(rawAlgDf.iterrows()):\n",
    "    vin = row[\"Vin6\"]\n",
    "    vinsFromUnder = df[df[\"VIN\"]==vin]\n",
    "\n",
    "\n",
    "    for index, match in vinsFromUnder.iterrows():\n",
    "        matchID = match[\"ID\"]\n",
    "        underwritingCreditScore = (int)(match[\"CreaditScore\"])\n",
    "        rawCreditScore = (int)(row[\"Score\"])\n",
    "\n",
    "        #we don't want to match if the scores are zero, since that means they are missing\n",
    "        if rawCreditScore==0:\n",
    "            continue\n",
    "\n",
    "        if underwritingCreditScore==rawCreditScore:\n",
    "            df.loc[df[\"ID\"]==matchID,\"Status\"]=row[\"ProcStatsCd\"]\n",
    "            df.loc[df[\"ID\"]==matchID,\"Delq\"]=row[\"Delq\"]\n",
    "            df.loc[df[\"ID\"]==matchID, \"APR\"] = int(row[\"Apr\"] * 100) if row[\"Apr\"] is not None else None #convert apr to an int\n",
    "\n",
    "df = df[(df['Status']=='CO') | (df['Status']=='CL')]\n",
    "df['Status'].replace(to_replace=['CO', 'CL'], value=[0,1], inplace=True)\n",
    "df['HomeOwner'].replace(to_replace=['N', 'Y'], value=[0,1], inplace=True)\n",
    "df['DelqPct'] = df.apply(lambda row : (100*row['Delq'])/row['OpeningBalance'],axis=1)\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "#TODO maybe put back: CreaditScore, CurrentPaymentsMade, DelqPct\n",
    "df = df[[\"OpeningBalance\",\"Salary\",\"Term\",\"VehicleYear\",\"LTV\",\"DTI\",\"TradelinesTotal\",\"TradelinesBalance\",\"Reposessions\",\"Bankrupcies\",\"Chageoff\",\"Mortgage\",\"NinetyDaysDelinquent\",\"InquiresTotal\",\"OpenTotal\",\"ClosedTotalTermsNotPaid\",\"LatePaymentHistory001230\",\"LatePaymentHistory001260\",\"LatePaymentHistory001290Plus\",\"PaidAccounts\",\"InquiriesLast6Months\",\"OpenTotalInBadStatus\",\"RentMortgage\",\"CashDown\",\"HomeOwner\", \"APR\", \"Status\"]]\n",
    "\n",
    "#outlier handling\n",
    "for col in df.columns:\n",
    "    if(col in [\"Status\", \"DelqPct\", \"CreaditScore\", \"HomeOwner\", \"Reposessions\", \"Chageoff\", \"APR\"]):\n",
    "        continue\n",
    "    percentiles = df[col].quantile([0.00, 0.999]).values\n",
    "    df.loc[df[col]<=percentiles[0], col] = percentiles[0]\n",
    "    df.loc[df[col]>=percentiles[1], col] = percentiles[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5045333  -0.46238504  0.43762614  0.0706154   0.36812794 -0.3398845\n",
      "  -0.51068203 -0.48779484 -0.38535294 -0.07440166 -0.87687381 -0.18950581\n",
      "  -0.14813506 -1.02116273 -0.30462629 -0.21213377 -0.65848734 -0.64790462\n",
      "  -0.47205863 -0.22641098 -0.96734764 -0.14792522  0.7143976  -0.56744881\n",
      "  -0.18950581  0.12963191]\n",
      " [-1.29619547 -0.59186782 -1.60872263  0.0706154   0.24155284 -0.36223408\n",
      "  -0.18149564 -0.3312031  -0.38535294 -0.07440166 -0.37555798 -0.18950581\n",
      "   0.74319505 -0.71988724  0.23387006  0.2659207  -0.65848734 -0.64790462\n",
      "   0.24573388 -0.4427535  -0.68610366  0.74333914  0.62543474 -0.56744881\n",
      "  -0.18950581 -0.6233156 ]\n",
      " [ 1.44337812  0.55239855  0.43762614  0.12803206 -1.37006257  0.22891219\n",
      "   0.03796195 -0.11681309  2.1414345  -0.07440166 -0.37555798 -0.18950581\n",
      "   0.07469747 -0.79520611 -0.48412507 -0.55075569  0.30149169  0.73669537\n",
      "  -0.47205863  0.63895906 -0.82672565  0.07489087 -0.5268462  -0.95585575\n",
      "  -0.18950581 -1.23936356]\n",
      " [ 0.4378291  -0.35096963  0.43762614  0.0706154   0.29687231 -0.29965527\n",
      "  -0.73013963 -0.51939754 -0.38535294 -0.07440166 -0.37555798 -0.18950581\n",
      "  -0.59380011  0.56053361 -0.66362385 -0.27189058 -0.65848734 -0.64790462\n",
      "  -0.47205863 -0.4427535   1.70447015 -0.5935574  -0.5268462  -0.56744881\n",
      "  -0.18950581 -0.76477846]\n",
      " [ 0.87199664 -0.65209236  0.43762614  0.0706154   2.04442216  0.18030187\n",
      "  -0.18149564 -0.38878595 -0.38535294 -0.07440166 -0.37555798 -0.18950581\n",
      "  -0.14813506 -0.56924949  0.41336884 -0.51091782 -0.65848734 -0.18637129\n",
      "  -0.07328501 -0.65909601 -0.82672565 -0.14792522  1.2481748  -0.95585575\n",
      "  -0.18950581 -0.32669991]\n",
      " [-0.830029   -0.34795841 -0.10806686  0.15674038 -0.06310762 -0.51476993\n",
      "  -0.18149564 -0.32801482  2.1414345  -0.07440166  0.62707368 -0.18950581\n",
      "   0.29753     1.53967897 -0.1251275   0.56470474 -0.01850132 -0.18637129\n",
      "  -0.15303974 -0.65909601  1.84509214  0.29770696 -0.5268462  -0.56744881\n",
      "  -0.18950581  0.12963191]\n",
      " [-0.78616623 -0.53164327 -0.38091337 -0.01550959  0.50995027 -0.1638816\n",
      "  -1.27878361 -0.56745865 -0.38535294 -0.07440166 -0.87687381 -0.18950581\n",
      "  -1.03946517 -1.17180048 -1.2021202  -1.0487291  -0.33849433 -0.64790462\n",
      "  -0.47205863 -0.65909601 -1.10796963 -1.03918958 -0.52260987 -0.95585575\n",
      "  -0.18950581  1.04229556]\n",
      " [ 0.55702377  0.04048991 -0.38091337  0.09932373 -0.33406917  1.94033093\n",
      "   2.78118187  0.74910538 -0.38535294 -0.07440166 -0.37555798 -0.18950581\n",
      "   0.29753     1.38904122  0.77236641  0.32567751  1.90145674  0.73669537\n",
      "   1.92058305  4.74946678  0.86073822  0.29770696  1.30324705 -0.56744881\n",
      "  -0.18950581 -0.76021514]\n",
      " [ 1.72119992 -0.0498469   1.25616565  0.18544871 -1.0318054   1.09104706\n",
      "  -0.07176685  0.11399223 -0.38535294 -0.07440166  0.62707368 -0.18950581\n",
      "  -0.14813506  3.04605644 -0.1251275  -0.23205271  0.30149169 -0.64790462\n",
      "  -0.47205863 -0.22641098  3.25131203 -0.14792522  1.59131729  1.37458586\n",
      "  -0.18950581 -1.71851198]\n",
      " [ 0.76760942 -0.47382771  0.43762614  0.09932373 -0.36729399  0.04620441\n",
      "  -0.83986842 -0.54371892 -0.38535294 -0.07440166 -0.87687381 -0.18950581\n",
      "  -0.81663264 -0.41861174 -0.84312263 -0.86945867 -0.01850132 -0.64790462\n",
      "  -0.47205863 -0.22641098 -0.26423769 -0.81637349 -0.5268462  -0.17904188\n",
      "  -0.18950581  1.01947897]]\n"
     ]
    }
   ],
   "source": [
    "#standarizing\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# X = MinMaxScaler().fit_transform(X)\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# ohe = OneHotEncoder()\n",
    "# y = ohe.fit_transform(y).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.iloc[:,:-1], df.iloc[:,-1:], test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "# sc_y = StandardScaler()\n",
    "# y_train = y_train.values.reshape((len(y_train), 1))\n",
    "# y_train = sc_y.fit_transform(y_train)\n",
    "# y_train = y_train.ravel()\n",
    "\n",
    "print(X_train[:10])\n",
    "# print(y_train[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6721, 26)\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rbf_layer_30 (RBFLayer)     (None, 50)                1350      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,401\n",
      "Trainable params: 1,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 15:31:17.028597: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 3s 11ms/step - loss: 0.4900 - accuracy: 0.5100\n",
      "Epoch 2/3\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 0.4900 - accuracy: 0.5100\n",
      "Epoch 3/3\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 0.4900 - accuracy: 0.5100\n",
      "29/53 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 15:31:23.350762: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "MIT Licence\n",
    "\n",
    "Zoghbi Abderraouf\n",
    "Change data to your location\n",
    "\"\"\"\n",
    "\n",
    "from keras import backend as K\n",
    "# from keras.engine.topology import Layer\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from keras.initializers import RandomUniform, Initializer, Constant\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class InitCentersRandom(Initializer):\n",
    "    \"\"\" Initializer for initialization of centers of RBF network\n",
    "        as random samples from the given data set.\n",
    "    # Arguments\n",
    "        X: matrix, dataset to choose the centers from (random rows\n",
    "          are taken as centers)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        assert shape[1] == self.X.shape[1]\n",
    "        idx = np.random.randint(self.X.shape[0], size=shape[0])\n",
    "        return self.X[idx, :]\n",
    "\n",
    "\n",
    "class RBFLayer(Layer):\n",
    "    \"\"\" Layer of Gaussian RBF units.\n",
    "    # Example\n",
    "    ```python\n",
    "        model = Sequential()\n",
    "        model.add(RBFLayer(10,\n",
    "                           initializer=InitCentersRandom(X),\n",
    "                           betas=1.0,\n",
    "                           input_shape=(1,)))\n",
    "        model.add(Dense(1))\n",
    "    ```\n",
    "    # Arguments\n",
    "        output_dim: number of hidden units (i.e. number of outputs of the\n",
    "                    layer)\n",
    "        initializer: instance of initiliazer to initialize centers\n",
    "        betas: float, initial value for betas\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_dim, initializer=None, betas=1.0, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.init_betas = betas\n",
    "        if not initializer:\n",
    "            self.initializer = RandomUniform(0.0, 1.0)\n",
    "        else:\n",
    "            self.initializer = initializer\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.centers = self.add_weight(name='centers',\n",
    "                                       shape=(self.output_dim, input_shape[1]),\n",
    "                                       initializer=self.initializer,\n",
    "                                       trainable=True)\n",
    "        self.betas = self.add_weight(name='betas',\n",
    "                                     shape=(self.output_dim,),\n",
    "                                     initializer=Constant(\n",
    "                                         value=self.init_betas),\n",
    "                                     # initializer='ones',\n",
    "                                     trainable=True)\n",
    "\n",
    "        super(RBFLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        C = K.expand_dims(self.centers)\n",
    "        H = K.transpose(C-K.transpose(x))\n",
    "        return K.exp(-self.betas * K.sum(H**2, axis=1))\n",
    "\n",
    "        # C = self.centers[np.newaxis, :, :]\n",
    "        # X = x[:, np.newaxis, :]\n",
    "\n",
    "        # diffnorm = K.sum((C-X)**2, axis=-1)\n",
    "        # ret = K.exp( - self.betas * diffnorm)\n",
    "        # return ret\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "    def get_config(self):\n",
    "        # have to define get_config to be able to use model_from_json\n",
    "        config = {\n",
    "            'output_dim': self.output_dim\n",
    "        }\n",
    "        base_config = super(RBFLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "from keras.initializers import Initializer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "class InitCentersKMeans(Initializer):\n",
    "    \"\"\" Initializer for initialization of centers of RBF network\n",
    "        by clustering the given data set.\n",
    "    # Arguments\n",
    "        X: matrix, dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, max_iter=100):\n",
    "        self.X = X\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        assert shape[1] == self.X.shape[1]\n",
    "\n",
    "        n_centers = shape[0]\n",
    "        km = KMeans(n_clusters=n_centers, max_iter=self.max_iter, verbose=0)\n",
    "        km.fit(self.X)\n",
    "        return km.cluster_centers_\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "import numpy as np, pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc_X = StandardScaler()\n",
    "# X_train = sc_X.fit_transform(X_train)\n",
    "# X_test = sc_X.transform(X_test)\n",
    "\n",
    "# sc_y = StandardScaler()\n",
    "# y_train = y_train.reshape((len(y_train), 1))\n",
    "# y_train = sc_y.fit_transform(y_train)\n",
    "# y_train = y_train.ravel()\n",
    "\n",
    "# print(X_train.shape)\n",
    "\n",
    "#initializer=InitCentersKMeans(X_train),\n",
    "model = Sequential()\n",
    "rbflayer = RBFLayer(50,\n",
    "                        betas=1.0,\n",
    "                        input_shape=(26,))\n",
    "model.add(rbflayer)\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('softmax'))\n",
    "opt = Adam(learning_rate=0.00000001)\n",
    "model.compile(loss='mean_squared_error',\n",
    "                  optimizer=opt, metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history1 = model.fit(X_train, y_train, epochs=3, batch_size=32)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(history1.history['accuracy'])\n",
    "# plt.plot(history1.history['loss'])\n",
    "# plt.title('train accuracy and loss')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['accuracy', 'loss'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# # saving to and loading from file\n",
    "# z_model = f\"Z_model.h5\"\n",
    "# print(f\"Save model to file {z_model} ... \", end=\"\")\n",
    "# model.save(z_model)\n",
    "# print(\"OK\")\n",
    "\n",
    "# #model already saved in file\n",
    "# from tensorflow.keras.models import  load_model\n",
    "# newmodel1= load_model(\"Zoghbio.h5\",\n",
    "#                           custom_objects={'RBFLayer': RBFLayer})\n",
    "# print(\"OK\")\n",
    "#\n",
    "# # Evaluate the model on the test data using `evaluate`\n",
    "# print(\"Evaluate on test data\")\n",
    "# results = newmodel1.evaluate(X_test, y_test, batch_size=32)\n",
    "# print(\"test loss:\", results[0])\n",
    "# print(\"test accuracy:\",results[1]*100,'%')\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "#Converting predictions to label\n",
    "# pred = list()\n",
    "# for i in range(len(y_pred)):\n",
    "#     pred.append(np.argmax(y_pred[i]))\n",
    "# #Converting one hot encoded test label to label\n",
    "# test = list()\n",
    "# for i in range(len(y_test)):\n",
    "#     test.append(np.argmax(y_test[i]))\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# a = accuracy_score(pred,test)\n",
    "# print('Test Accuracy is:', a*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}